{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1196732,"sourceType":"datasetVersion","datasetId":681625}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cat /opt/conda/lib/python3.7/site-packages/efficientnet/keras.py","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:04:12.123665Z","iopub.execute_input":"2024-01-09T04:04:12.124222Z","iopub.status.idle":"2024-01-09T04:04:13.127224Z","shell.execute_reply.started":"2024-01-09T04:04:12.124189Z","shell.execute_reply":"2024-01-09T04:04:13.126140Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cat: /opt/conda/lib/python3.7/site-packages/efficientnet/keras.py: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_ending = '''from . import inject_keras_modules, init_tfkeras_custom_objects\nfrom . import model\n\nfrom .preprocessing import center_crop_and_resize\n\nEfficientNetB0 = inject_keras_modules(model.EfficientNetB0)\nEfficientNetB1 = inject_keras_modules(model.EfficientNetB1)\nEfficientNetB2 = inject_keras_modules(model.EfficientNetB2)\nEfficientNetB3 = inject_keras_modules(model.EfficientNetB3)\nEfficientNetB4 = inject_keras_modules(model.EfficientNetB4)\nEfficientNetB5 = inject_keras_modules(model.EfficientNetB5)\nEfficientNetB6 = inject_keras_modules(model.EfficientNetB6)\nEfficientNetB7 = inject_keras_modules(model.EfficientNetB7)\n\npreprocess_input = inject_keras_modules(model.preprocess_input)\n\ninit_tfkeras_custom_objects()'''\nwith open('/opt/conda/lib/python3.7/site-packages/efficientnet/keras.py', mode='w') as file:\n    file.write(submission_ending)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#!pip install opencv-python\n!pip install patchify\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom PIL import Image\nfrom patchify import patchify\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom matplotlib import pyplot as plt\nimport random \n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Python3 code to demonstrate\n# check for unique values\n# Using len() + set() + values()\n\n# initializing dictionary\ntest_dict = {'Manjeet': 1, 'Akash': 2, 'Punnet': 3, 'Manjeet': 4}\ntest_dict2 = {10: 'Manjeet', 2: 'Akash', 3: 'Dalton'}\n\n\n\n# printing original dictionary\nprint(\"The original dictionary : \" + str(test_dict))\n\nprint(\"The original dictionary : \" + str(test_dict2))\n\n\n# using len() + set() + values()\n# check for unique values\n\n#flag = len(test_dict) != len(set(test_dict.items()))\nflag = len(test_dict) != len(set(test_dict.values()))\n# print(set(test_dict.items()))\n# print(set(test_dict2.items()))\n\n\n\n\n# print result\nprint(\"Does dictionary contain repetition : \" + str(flag))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:04:38.542773Z","iopub.execute_input":"2024-01-09T04:04:38.543840Z","iopub.status.idle":"2024-01-09T04:04:38.552460Z","shell.execute_reply.started":"2024-01-09T04:04:38.543779Z","shell.execute_reply":"2024-01-09T04:04:38.551475Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The original dictionary : {'Manjeet': 4, 'Akash': 2, 'Punnet': 3}\nThe original dictionary : {10: 'Manjeet', 2: 'Akash', 3: 'Dalton'}\nDoes dictionary contain repetition : False\n","output_type":"stream"}]},{"cell_type":"code","source":"minmaxscaler = MinMaxScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_root_folder = '/kaggle/input/semantic-segmentation-of-aerial-imagery'\ndataset_name = 'Semantic segmentation dataset'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path, subdirs, files in os.walk(dataset_root_folder):\n    dir_name = path.split(os.path.sep)[-1]\n    #print(dir_name)\n    if dir_name == 'masks': # would be images for image masks\n        images = os.listdir(path)\n        #print(images)\n        \n        \n        for i, image_name in enumerate(images):\n            if(image_name.endswith('.png')): # would be jpg for image tiles\n                print(image_name)\n            \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_patch_size = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile 2/images/image_part_005.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(image.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"??patchify","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_patches = patchify(image, (image_patch_size, image_patch_size, 3), step = image_patch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((image_patches.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minmaxscaler.fit_transform??","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_x = image_patches[0,0,:,:]\nimage_y = minmaxscaler.fit_transform(image_x.reshape(-1,image_x.shape[-1])).reshape(image_x.shape)\nimage_y[0]\n\n#minmaxscaler = MinMaxScaler()\n#minmaxscaler.fit_transform(image_x.reshape(-1,))\n\n#MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(Image.fromarray(image))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(image.shape[0]//image_patch_size)*image_patch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = []\nmask_dataset = []\n\nfor image_type in ['images', 'masks']:\n    if image_type == 'images':\n        image_extension = 'jpg'\n    elif image_type == 'masks':\n        image_extension = 'png' #could also be png\n            \n    for tile_id in range(1,8):\n        for image_id in range(1, 20):\n            image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/{image_type}/image_part_00{image_id}.{image_extension}', 1)\n            if image is not None:\n                if image_type == 'masks':\n                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                #print(image.shape)\n                size_x = (image.shape[1]//image_patch_size)*image_patch_size\n                size_y = (image.shape[0]//image_patch_size)*image_patch_size # patchify ims into multiples of 256(or 512, depends)\n                #print(\"{} --- {} - {}\".format(image.shape, size_x, size_y))\n                image = Image.fromarray(image)\n                image = image.crop((0, 0, size_x, size_y))\n                #print(\"({}, {})\".format(image.size[1], image.size[0])) \n                image = np.array(image)\n                patched_images = patchify(image, (image_patch_size, image_patch_size, 3), step = image_patch_size)\n                #print(len(patched_images))\n                for i in range(patched_images.shape[0]):\n                    for j in range(patched_images.shape[1]):\n                        if image_type == 'images':\n                            individual_patched_image = patched_images[i,j,:,:]\n                            #print(individual_patched_image.shape)\n                            individual_patched_image = minmaxscaler.fit_transform(individual_patched_image.reshape(-1, individual_patched_image.shape[-1])).reshape(individual_patched_image.shape)\n                            #print(individual_patched_image.shape)\n                            individual_patched_image = individual_patched_image[0]\n                            #print(individual_patched_image.shape)\n                            image_dataset.append(individual_patched_image)\n                        elif image_type == 'masks':\n                            individual_patched_mask = patched_images[i,j,:,:]\n                            individual_patched_mask = individual_patched_mask[0]\n                            mask_dataset.append(individual_patched_mask)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(image_dataset))\nprint(len(mask_dataset))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                                                 # Now let's render images in both of our datasets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = np.array(image_dataset)\nmask_dataset = np.array(mask_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mask_dataset.shape)\nprint(image_dataset.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_image_id = random.randint(0, len(image_dataset))\nplt.figure(figsize=(14,8))\nplt.subplot(121)\nplt.imshow(image_dataset[random_image_id])\nplt.subplot(122)\nplt.imshow(mask_dataset[random_image_id])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n lower_dim_slice = arr2d[0, 1:]\n lower_dim_slice \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                                                                    # Processing mask labels using one hot encoding","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_building = '#3C1098' #hex code of the class\nclass_building = class_building.lstrip('#')\nclass_building = np.array(tuple(int(class_building[i:i+2],16)for i in (0,2,4)))\nprint(class_building)\n\nclass_land = '8429F6'\nclass_land = class_land.lstrip('#')\nclass_land= np.array(tuple(int(class_land[i:i+2],16)for i in (0,2,4)))\nprint(class_land)\n\nclass_road = '#6EC1E4'\nclass_road = class_road.lstrip('#')\nclass_road = np.array(tuple(int(class_road[i:i+2],16)for i in (0,2,4)))\nprint(class_road)\n\nclass_vegetation = '#FEDD3A'\nclass_vegetation = class_vegetation.lstrip('#')\nclass_vegetation = np.array(tuple(int(class_vegetation[i:i+2],16)for i in (0,2,4)))\nprint(class_vegetation)\n\nclass_water= '#E2A929'\nclass_water= class_water.lstrip('#')\nclass_water= np.array(tuple(int(class_water[i:i+2],16)for i in (0,2,4)))\nprint(class_water)\n\nclass_unlabelled= '#9B9B9B'\nclass_unlabelled= class_unlabelled.lstrip('#')\nclass_unlabelled= np.array(tuple(int(class_unlabelled[i:i+2],16)for i in (0,2,4)))\nprint(class_unlabelled)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rgb_to_label(label):\n    label_segment = np.zeros(label.shape, dtype=np.uint8)\n    label_segment[np.all(label == class_water, axis=-1)] = 0\n    label_segment[np.all(label == class_land, axis=-1)] = 1\n    label_segment[np.all(label == class_road, axis=-1)] = 2\n    label_segment[np.all(label == class_building, axis=-1)] = 3\n    label_segment[np.all(label == class_vegetation, axis=-1)] = 4\n    label_segment[np.all(label == class_unlabelled, axis=-1)] = 5\n    #print(label_segment.shape)\n    label_segment = label_segment[:,:,0]\n    print(label_segment.shape)\n    return label_segment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label= rgb_to_label(mask_dataset[500])\ntest_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = []\nfor i in range(mask_dataset.shape[0]):\n    label = rgb_to_label(mask_dataset[i])\n    labels.append(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(len(labels))\n#print(labels)\n#print(labels[0][0,0])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.array(labels)\n#print(labels.shape)\n#print(labels[0])\nlabels = np.expand_dims(labels, axis=3)\n#print(labels[0])\n#print(labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_image_id = random.randint(0, len(image_dataset))\nplt.figure(figsize=(14,8))\nplt.subplot(121)\nplt.imshow(image_dataset[random_image_id])\nplt.subplot(122)\n#plt.imshow(mask_dataset[random_image_id])\nplt.imshow(labels[random_image_id][:,:,0])\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_classes = len(np.unique(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = tf.keras.utils.to_categorical([0, 1, 2, 3,1,5], num_classes=6)\na = tf.constant(a, shape=[6, 6])\nprint(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_categorical??","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_categorical_dataset = to_categorical(labels, num_classes = total_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_categorical_dataset.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"master_training_dataset = image_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(master_training_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_height = X_train.shape[1]\nimage_width = X_train.shape[2]\nimage_channels = X_train.shape[3]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(image_height)\nprint(image_width)\nprint(image_channels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"                                             # ANDDDD THAT'S FOR THE DATA PRE PROCESSING PART NOW LET'S JUMP ON TO THE MODEL BUILDING PART","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#      Building up the model","metadata":{}},{"cell_type":"code","source":"!pip install -U segmentation-models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\nfrom keras.layers import concatenate, BatchNormalization, Dropout, Lambda","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we'll setup custom eval matrix, Jaccard Index/ Intersection Over Union, see https://deepai.org/machine-learning-glossary-and-terms/jaccard-index, sorry too lazy to make it a hyperlink","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from keras.models","metadata":{}},{"cell_type":"code","source":"def jaccard_coef(y_true, y_pred):\n    y_true_flatten=K.flatten(y_true)\n    y_true_pred=K.flatten(y_pred)\n    intersection = K.sum(y_true_flatten * y_true_pred)\n    final_coef_val = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_true_pred) - intersection + 1.0)\n    return final_coef_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multi_unet_model(n_classes=5, image_height=256, image_width=256, image_channels=1):\n    inputs = Input((image_height, image_width, image_channels))\n    source_input = inputs\n    \n    c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(source_input) \n    c1 = Dropout(0.2)(c1) # experiment with this one to see what maximizes the IOU coefficient\n    c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c1)\n    p1 = MaxPooling2D((2,2))(c1)\n    \n    c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(p1)\n    c2 = Dropout(0.2)(c2)\n    c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c2)\n    p2 = MaxPooling2D((2,2))(c2)\n    \n    c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(p2)\n    c3 = Dropout(0.2)(c3)\n    c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c3)\n    p3 = MaxPooling2D((2,2))(c3)\n    \n    c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(p3)\n    c4 = Dropout(0.2)(c4)\n    c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c4)\n    p4 = MaxPooling2D((2,2))(c4)\n    \n    c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(p4)\n    c5 = Dropout(0.2)(c5)\n    c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c5)\n   \n    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n    u6 =  concatenate([u6, c4])\n    c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(u6)\n    c6 = Dropout(0.2)(c6)\n    c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c6)\n    \n    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n    u7 =  concatenate([u7, c3])\n    c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(u7)\n    c7 = Dropout(0.2)(c7)\n    c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c7)\n    \n    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n    u8 =  concatenate([u8, c2])\n    c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(u8)\n    c8 = Dropout(0.2)(c8)\n    c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c8)\n    \n    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n    u9 =  concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(u9)\n    c9 = Dropout(0.2)(c9)\n    c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding =\"same\")(c9)\n    \n    outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n    models = Model(inputs=[inputs], outputs=[outputs])\n    return models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = [\"accuracy\", jaccard_coef]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_deep_learning_model():\n    return multi_unet_model(n_classes=total_classes, image_height=image_height,image_width=image_width,image_channels=image_channels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_deep_learning_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.get_config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#                Generating Loss Function","metadata":{}},{"cell_type":"code","source":"weights = [0.166, 0.166, 0.166, 0.166, 0.166,0.166]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_ending = '''from . import inject_keras_modules, init_tfkeras_custom_objects\nfrom . import model\n\nfrom .preprocessing import center_crop_and_resize\n\nEfficientNetB0 = inject_keras_modules(model.EfficientNetB0)\nEfficientNetB1 = inject_keras_modules(model.EfficientNetB1)\nEfficientNetB2 = inject_keras_modules(model.EfficientNetB2)\nEfficientNetB3 = inject_keras_modules(model.EfficientNetB3)\nEfficientNetB4 = inject_keras_modules(model.EfficientNetB4)\nEfficientNetB5 = inject_keras_modules(model.EfficientNetB5)\nEfficientNetB6 = inject_keras_modules(model.EfficientNetB6)\nEfficientNetB7 = inject_keras_modules(model.EfficientNetB7)\n\npreprocess_input = inject_keras_modules(model.preprocess_input)\n\ninit_tfkeras_custom_objects()'''\nwith open('/opt/conda/lib/python3.7/site-packages/efficientnet/keras.py', mode='w') as file:\n    file.write(submission_ending)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! /opt/conda/lib/python3.7/site-packages/efficientnet/keras.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Segmentation models : using Keras as framework****","metadata":{}},{"cell_type":"code","source":"dice_loss= sm.losses.DiceLoss(class_weights=weights)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"focal_loss= sm.losses.CategoricalFocalLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_loss = dice_loss + (1 * focal_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Compilation","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session() # setup the backend session\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",loss=total_loss, metrics = metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file=\"satellite-model-lot.png\",show_shapes=True,show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom IPython.display import clear_output\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlotLoss(keras.callbacks.Callback):\n    \n    def on_train_begin(self, logs={}):\n        \n        \n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n\n        self.jaccard_coef = []\n        self.val_jaccard_coef = []\n\n        self.fig = plt.figure()\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        # self.losses.append(logs.get('loss'))\n        # self.val_losses.append(logs.get('val_loss'))\n\n        self.jaccard_coef.append(logs.get('jaccard_coef'))\n        self.val_jaccard_coef.append(logs.get('val_jaccard_coef'))\n\n        self.i += 1\n    \n        clear_output(wait=True)\n        # plt.plot(self.x, self.losses, label=\"loss\")\n        # plt.plot(self.x, self.val_losses, label=\"val_loss\")\n\n        plt.plot(self.x, self.jaccard_coef, label=\"jaccard_coef\")\n        plt.plot(self.x, self.val_jaccard_coef, label=\"val_jaccard_coef\")\n\n        plt.legend()\n        plt.show();\n\nplot_loss = PlotLoss()\n            \n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(X_train, y_train, batch_size=8, verbose=1, epochs=15, validation_data=(X_test,y_test),shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_a = model_history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history_a.history['loss']\nval_loss = history_a.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label=\"Training Loss\")\nplt.plot(epochs, val_loss, 'r', label=\"Validation Loss\")\nplt.title(\"Training Vs validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_coef = history_a.history['jaccard_coef']\nval_jaccard_coef = history_a.history['val_jaccard_coef']\nepochs = range(1, len(jaccard_coef) + 1)\nplt.plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\nplt.plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\nplt.title(\"Training Vs validation IoU\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"IoU\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history.params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_argmax = np.argmax(y_pred, axis=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_argmax = np.argmax(y_test, axis=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing test and prediction results","metadata":{}},{"cell_type":"code","source":"# we can co mpare side by side the predicted mask image and test mask image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_number = random.randint(0,(len(X_test)))\ntest_image = X_test[test_image_number]\nground_truth_image = y_test_argmax[test_image_number]\n\ntest_image_input = np.expand_dims(test_image, 0)\n\nprediction = model.predict(test_image_input)\n#prediction = saved_model.predict(test_image_input)\npredicted_image = np.argmax(prediction, axis=3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_image = predicted_image[0,:,:]\npredicted_image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(ground_truth_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(predicted_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\nplt.subplot(231)\nplt.title(\"Original Test Image\")\nplt.imshow(test_image)\nplt.subplot(232)\nplt.title(\"Original Masked Image\")\nplt.imshow(ground_truth_image)\nplt.subplot(233)\nplt.title(\"Predicted Image\")\nplt.imshow(predicted_image)           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"satellite_segmentation_full.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model deployment and reload","metadata":{}},{"cell_type":"code","source":"model.save('Satellite_image_segmentation.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/Satellite_image_segmentation.h5'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -lah /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_model = load_model(model_path, custom_objects=({'dice_loss_plus_1focal_loss':total_loss,'jaccard_coef':jaccard_coef}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.loss.name # very important","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict the mask of any image from Google Map/Earth","metadata":{}},{"cell_type":"code","source":"!wget -nd -r -P /kaggle/working -A jpg https://www.allallsoft.com/gmd/support/mapviewer2.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/working/mapviewer2.jpg'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Image.open(image_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open(image_path)\nimage = image.resize((256,256))\nimage = np.array(image)\nimage = np.expand_dims(image,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = saved_model.predict(image)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_image = np.argmax(prediction, axis=3)\npredicted_image = predicted_image[0,:,:]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\nplt.subplot(221)\nplt.title(\"Original Test Image\")\nplt.imshow(Image.open(image_path))\nplt.subplot(222)\nplt.title(\"Predicted Image\")\nplt.imshow(predicted_image)           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Collecting activation and gradient output from our model","metadata":{}},{"cell_type":"code","source":"!pip install keract","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keract as ke","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activations = ke.get_activations(saved_model, image,nodes_to_evaluate=None, output_format='simple',auto_compile=True,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/activations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -lah /kaggle/activations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ke.display_activations(activations, cmap='virdis',save=True, directory='/kaggle/activations')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Image.open('path_of_activation_images'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -nd -r -P /kaggle/working -A jpg https://mappinglondon.co.uk/wp-content/uploads/2011/02/googlemaps_britishmuseum.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -lah /kaggle/working/googlemaps_britishmuseum.jpg\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/heatmap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open('image_path')\nimage = image.resize((256,256))\nimage_as_array = np.array(image)\nimage_as_array = image_as_array.astype(np.float32)\nke.display_heatmaps(activations, image_as_array, save=True, directory='/kaggle/heatmap')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}